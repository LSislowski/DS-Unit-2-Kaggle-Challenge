{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.9"
    },
    "colab": {
      "name": "LS_DS_223_assignment.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lM73fLVTA9BM"
      },
      "source": [
        "Lambda School Data Science\n",
        "\n",
        "*Unit 2, Sprint 2, Module 3*\n",
        "\n",
        "---\n",
        "<p style=\"padding: 10px; border: 2px solid red;\">\n",
        "    <b>Before you start:</b> Today is the day you should submit the dataset for your Unit 2 Build Week project. You can review the guidelines and make your submission in the Build Week course for your cohort on Canvas.</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HM6heHyA9BN"
      },
      "source": [
        "   !pip install category_encoders==2.*\n",
        "   !pip install pandas-profiling==2.*"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvUlEcaHCrrK"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from category_encoders import OneHotEncoder, OrdinalEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import cross_val_score, validation_curve \n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV \n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from pandas_profiling import ProfileReport\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "pd.options.display.max_rows = 100"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnbRIRgoA9BO"
      },
      "source": [
        "# Module Project: Hyperparameter Tuning\n",
        "\n",
        "This sprint, the module projects will focus on creating and improving a model for the Tanazania Water Pump dataset. Your goal is to create a model to predict whether a water pump is functional, non-functional, or needs repair.\n",
        "\n",
        "Dataset source: [DrivenData.org](https://www.drivendata.org/competitions/7/pump-it-up-data-mining-the-water-table/).\n",
        "\n",
        "## Directions\n",
        "\n",
        "The tasks for this project are as follows:\n",
        "\n",
        "- **Task 1:** Use `wrangle` function to import training and test data.\n",
        "- **Task 2:** Split training data into feature matrix `X` and target vector `y`.\n",
        "- **Task 3:** Establish the baseline accuracy score for your dataset.\n",
        "- **Task 4:** Build `clf_dt`.\n",
        "- **Task 5:** Build `clf_rf`.\n",
        "- **Task 6:** Evaluate classifiers using k-fold cross-validation.\n",
        "- **Task 7:** Tune hyperparameters for best performing classifier.\n",
        "- **Task 8:** Print out best score and params for model.\n",
        "- **Task 9:** Create `submission.csv` and upload to Kaggle.\n",
        "\n",
        "You should limit yourself to the following libraries for this project:\n",
        "\n",
        "- `category_encoders`\n",
        "- `matplotlib`\n",
        "- `pandas`\n",
        "- `pandas-profiling`\n",
        "- `sklearn`\n",
        "\n",
        "# I. Wrangle Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0s-ATylA9BO"
      },
      "source": [
        "train = pd.merge(pd.read_csv('train_features.csv', na_values=[0, -2.00000e-08], parse_dates=['date_recorded']), pd.read_csv('train_labels.csv', na_values=[0, -2.00000e-08]))\n",
        "test = pd.read_csv('test_features.csv', na_values=[0, -2.00000e-08], parse_dates=['date_recorded'])\n",
        "\n",
        "def wrangle(df):\n",
        "    \n",
        "    # Set id as index\n",
        "    df.set_index('id', inplace=True)\n",
        "\n",
        "    # Drop constant columns\n",
        "    df.drop(columns= 'recorded_by', inplace=True)\n",
        "\n",
        "    # # Drop duplicate columns\n",
        "    #df.drop(columns= 'quantity group')\n",
        "\n",
        "    # Create age feature\n",
        "    df['pump_age'] = df['date_recorded'].dt.year - df['construction_year']\n",
        "    df.drop(columns='date_recorded', inplace=True)\n",
        "\n",
        "    #Drop HCCCs\n",
        "    cutoff = 100\n",
        "    drop_cols = [col for col in df.select_dtypes('object').columns\n",
        "                 if df[col].nunique() > cutoff]\n",
        "    df.drop(columns=drop_cols, inplace=True)\n",
        "\n",
        "    # Strip differing words between the two datasets\n",
        "    df.drop(columns= ['waterpoint_type_group', 'payment_type'], inplace=True)\n",
        "    \n",
        "    #Drop duplicate columns and account for the difference in X_test\n",
        "    dupe_cols = [col for col in df.head(15).T.duplicated().index\n",
        "                 if df.head(15).T.duplicated()[col]]\n",
        "    df.drop(columns=dupe_cols, inplace=True)             \n",
        "\n",
        "    # Drop num_private since there are 98% missing values in that column\n",
        "\n",
        "    df.drop(columns='num_private', inplace=True)\n",
        "\n",
        "    return df\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nI35xHKLA9BP"
      },
      "source": [
        "**Task 1:** Using the above `wrangle` function to read `train_features.csv` and `train_labels.csv` into the DataFrame `df`, and `test_features.csv` into the DataFrame `X_test`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwIxzAx0A9BP"
      },
      "source": [
        "df = wrangle(train)\n",
        "X_test = wrangle(test)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8qwoT38A9BP"
      },
      "source": [
        "# II. Split Data\n",
        "\n",
        "**Task 2:** Split your DataFrame `df` into a feature matrix `X` and the target vector `y`. You want to predict `'status_group'`.\n",
        "\n",
        "**Note:** You won't need to do a train-test split because you'll use cross-validation instead."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eu_a9ETA9BP"
      },
      "source": [
        "# Split\n",
        "target = 'status_group'\n",
        "\n",
        "y = train[target]\n",
        "X = train.drop(columns = target)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8Oyf5FdDf52"
      },
      "source": [
        "X_train,X_val,y_train,y_val = train_test_split(X,y,test_size=0.2,random_state=42)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCIXJlUSA9BQ"
      },
      "source": [
        "# III. Establish Baseline\n",
        "\n",
        "**Task 3:** Since this is a **classification** problem, you should establish a baseline accuracy score. Figure out what is the majority class in `y_train` and what percentage of your training observations it represents."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnF_DdotA9BQ",
        "outputId": "9dfe4bf3-707b-4773-abf3-b402595d1f77",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "baseline_acc = y_train.value_counts(normalize = True).max()\n",
        "print('Baseline Accuracy Score:', baseline_acc)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Baseline Accuracy Score: 0.5440867003367004\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-ufrJeFA9BQ"
      },
      "source": [
        "# IV. Build Models\n",
        "\n",
        "**Task 4:** Build a `Pipeline` named `clf_dt`. Your `Pipeline` should include:\n",
        "\n",
        "- an `OrdinalEncoder` transformer for categorical features.\n",
        "- a `SimpleImputer` transformer fot missing values.\n",
        "- a `DecisionTreeClassifier` Predictor.\n",
        "\n",
        "**Note:** Do not train `clf_dt`. You'll do that in a subsequent task. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "af4Qz3HBA9BQ"
      },
      "source": [
        "clf_dt = make_pipeline(\n",
        "            OrdinalEncoder(),\n",
        "            SimpleImputer(),\n",
        "            DecisionTreeClassifier(random_state=42))\n"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ml_j9tg5A9BR"
      },
      "source": [
        "**Task 5:** Build a `Pipeline` named `clf_rf`. Your `Pipeline` should include:\n",
        "\n",
        "- an `OrdinalEncoder` transformer for categorical features.\n",
        "- a `SimpleImputer` transformer fot missing values.\n",
        "- a `RandomForestClassifier` predictor.\n",
        "\n",
        "**Note:** Do not train `clf_rf`. You'll do that in a subsequent task. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ypp8w0GJA9BR"
      },
      "source": [
        "clf_rf = make_pipeline(\n",
        "            OrdinalEncoder(),\n",
        "            SimpleImputer(),\n",
        "            RandomForestClassifier(random_state=42))\n",
        "\n"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppbuAlYLA9BR"
      },
      "source": [
        "# V. Check Metrics\n",
        "\n",
        "**Task 6:** Evaluate the performance of both of your classifiers using k-fold cross-validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmaIwplaA9BR"
      },
      "source": [
        "cv_scores_dt = cross_val_score(clf_dt, X, y, cv=5, n_jobs=-1)\n",
        "cv_scores_rf = cross_val_score(clf_rf, X, y, cv=5, n_jobs=-1)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJpDOOTQA9BR",
        "outputId": "b1aff719-d417-4774-a77e-e402736b5539",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print('CV scores DecisionTreeClassifier')\n",
        "print(cv_scores_dt)\n",
        "print('Mean CV accuracy score:', cv_scores_dt.mean())\n",
        "print('STD CV accuracy score:', cv_scores_dt.std())"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CV scores DecisionTreeClassifier\n",
            "[0.74726431 0.75073653 0.74705387 0.75178872 0.74558081]\n",
            "Mean CV accuracy score: 0.7484848484848484\n",
            "STD CV accuracy score: 0.0023645933317487924\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5rp3y1FA9BS",
        "outputId": "6db36ac0-0184-4e13-d506-6a4a5d7d286c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print('CV score RandomForestClassifier')\n",
        "print(cv_scores_rf)\n",
        "print('Mean CV accuracy score:', cv_scores_rf.mean())\n",
        "print('STD CV accuracy score:', cv_scores_rf.std())"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CV score RandomForestClassifier\n",
            "[0.79776936 0.79829545 0.79808502 0.80439815 0.79724327]\n",
            "Mean CV accuracy score: 0.7991582491582492\n",
            "STD CV accuracy score: 0.0026438213425150395\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZWyd5kvA9BS"
      },
      "source": [
        "# VI. Tune Model\n",
        "\n",
        "**Task 7:** Choose the best performing of your two models and tune its hyperparameters using a `RandomizedSearchCV` named `model`. Make sure that you include cross-validation and that `n_iter` is set to at least `25`.\n",
        "\n",
        "**Note:** If you're not sure which hyperparameters to tune, check the notes from today's guided project and the `sklearn` documentation. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bINFCOm_HgUW"
      },
      "source": [
        "param_grid = {\n",
        "    'simpleimputer__strategy':['mean','median'],\n",
        "    'randomforestclassifier__max_depth': range(12, 20, 1),\n",
        "    'randomforestclassifier__n_estimators': range(65, 75, 1)}"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUeHwEvPA9BS",
        "outputId": "57520fc3-78b3-4d38-af20-d20f455a758c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = RandomizedSearchCV(\n",
        "    clf_rf,\n",
        "    param_distributions = param_grid,\n",
        "    n_iter = 40,\n",
        "    cv = 5,\n",
        "    n_jobs = -1,\n",
        "    verbose = 1\n",
        ")\n",
        "\n",
        "model.fit(X,y)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  3.2min\n",
            "[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed: 13.2min\n",
            "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed: 13.5min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=5, error_score=nan,\n",
              "                   estimator=Pipeline(memory=None,\n",
              "                                      steps=[('ordinalencoder',\n",
              "                                              OrdinalEncoder(cols=None,\n",
              "                                                             drop_invariant=False,\n",
              "                                                             handle_missing='value',\n",
              "                                                             handle_unknown='value',\n",
              "                                                             mapping=None,\n",
              "                                                             return_df=True,\n",
              "                                                             verbose=0)),\n",
              "                                             ('simpleimputer',\n",
              "                                              SimpleImputer(add_indicator=False,\n",
              "                                                            copy=True,\n",
              "                                                            fill_value=None,\n",
              "                                                            missing_values=nan,\n",
              "                                                            strategy='mean',\n",
              "                                                            verbose=0)...\n",
              "                                                                     verbose=0,\n",
              "                                                                     warm_start=False))],\n",
              "                                      verbose=False),\n",
              "                   iid='deprecated', n_iter=40, n_jobs=-1,\n",
              "                   param_distributions={'randomforestclassifier__max_depth': range(12, 20),\n",
              "                                        'randomforestclassifier__n_estimators': range(65, 75),\n",
              "                                        'simpleimputer__strategy': ['mean',\n",
              "                                                                    'median']},\n",
              "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
              "                   return_train_score=False, scoring=None, verbose=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2XljE7HA9BS"
      },
      "source": [
        "**Task 8:** Print out the best score and best params for `model`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImFLDZsGA9BS",
        "outputId": "54c6f996-720b-4d9c-ded7-6edabc511efb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "best_score = model.best_score_\n",
        "best_params = model.best_params_\n",
        "\n",
        "print('Best score for `model`:', best_score)\n",
        "print('Best params for `model`:', best_params)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best score for `model`: 0.8042087542087542\n",
            "Best params for `model`: {'simpleimputer__strategy': 'mean', 'randomforestclassifier__n_estimators': 66, 'randomforestclassifier__max_depth': 19}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqbAZu7sA9BS"
      },
      "source": [
        "# Communicate Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2y5_WKgA9BT"
      },
      "source": [
        "**Task 9:** Create a DataFrame `submission` whose index is the same as `X_test` and that has one column `'status_group'` with your predictions. Next, save this DataFrame as a CSV file and upload your submissions to our competition site. \n",
        "\n",
        "**Note:** Check the `sample_submission.csv` file on the competition website to make sure your submissions follows the same formatting. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-BWOEXZA9BT"
      },
      "source": [
        "y_pred = model.predict(X_test)\n",
        "submission = pd.DataFrame({'status_group':y_pred}, index=X_test.index)\n",
        "datestamp = pd.Timestamp.now().strftime('%Y-%m-%d_%H%M_')\n",
        "submission.to_csv(f'{datestamp}submission_Luke_Sislowski.csv')"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwC8USfbadbC",
        "outputId": "19b87b8f-4dbd-4595-f955-690cef531c22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "source": [
        "# Download CSV\n",
        "\n",
        "from google.colab import files\n",
        "files.download(f'{datestamp}submission_Luke_Sislowski.csv')"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_7f93900b-2c12-4eaf-ab8e-eb4d0994d0c0\", \"2021-07-14_2346_submission_Luke_Sislowski.csv\", 222225)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}